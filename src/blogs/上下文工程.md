---
title: 上下文工程
category: 博客
---

## 上下文工程

### 概述

上下文指的是从大型语言模型（LLM）中采样时包含的标记集。当前的工程问题是优化这些标记的效用，以克服 LLM 的固有约束，从而持续实现期望的结果。有效管理 LLM 通常需要从上下文角度思考——换句话说：考虑在任何给定时间 LLM 可用的整体状态以及该状态可能产生的潜在行为。

### 有效上下文的结构

1）**恰当的提示**：有效的系统提示应避免过于复杂或过于模糊两个极端。建议使用XML标签或Markdown标题等技术，将提示语划分为不同的部分（如背景信息、指令、工具指导等），清晰地描述预期行为

2）**精简工具集**：避免给agent提供过多冗余的工具集，为agent精选一套最小可行工具集也可以带来更可靠的维护和长期交互中的上下文修剪。

3）**few-shot prompting**：是一种广为人知的最佳实践。然而，团队通常会往提示中塞满各种边缘案例，试图明确说明 LLM 在特定任务中应遵循的所有可能规则。相反，我们建议努力策划一组多样化、规范化的示例，这些示例能有效展现代理的预期行为。对于 LLM 而言，示例就是“千言万语”的“图画”。

### 上下文检索和代理式搜索

Claude Code 是一个采用这种混合模型的智能体：CLAUDE.md 文件被直接放入上下文中，而 glob 和 grep 等原语则允许它导航其环境并即时检索文件，有效绕过了陈旧索引和复杂语法树的问题。

### 长时程任务中的上下文工程

1）**压缩**：将一个接近上下文窗口限制的对话内容进行总结，并使用总结内容重新初始化一个新的上下文窗口。压缩通常作为上下文工程中的第一个杠杆，以推动更好的长期连贯性。其核心在于，压缩以高保真方式提炼上下文窗口的内容，使代理能够以最小的性能下降继续工作。

2）**结构化笔记记录**：代理定期将笔记写入存储在上下文窗口之外的内存中。这些笔记在稍后时间会被拉回上下文窗口。

3）**子智能体架构**：主agent负责与高层计划协调，而子agent则执行深度的技术工作或使用工具查找相关信息。每个子agent可能会进行广泛的探索，使用数万甚至更多的 token，但只返回其工作的精炼摘要（通常为 1,000-2,000 个 token）。

**这些技术取决于任务：压缩适合对话流，做笔记适合具有明确里程碑的迭代开发，多agent适合复杂研究。**

### 结论

上下文工程代表着我们使用 LLMs 构建方式的根本性转变。随着模型能力的提升，挑战不仅在于设计完美的提示——更在于精心管理在每一步中进入模型有限注意力预算的信息。无论是为长时任务实现压缩，设计高效的工具，还是让智能体即时探索环境，指导原则始终不变：找到最小的高信号标记集，以最大化期望结果的概率。